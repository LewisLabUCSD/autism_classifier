colnames(resMapped)=c("Fnode","Snode")
name=.myNetCombination(resMapped)
resMapped=resMapped[!duplicated(name),]
head(resMapped)
dim(resMapped)
x=resMapped$Snode[duplicated(resMapped$Snode)]
x=unique(x)
resMapped[resMapped$Snode==x[1],]
resMapped=data.frame(source=1,target=2,stringsAsFactors = F)
dsubDirList=paste0("~/OneDrive - UC San Diego/stock_analysis/SEC/data/",dir("~/OneDrive - UC San Diego/stock_analysis/SEC/data/"),"/sub.txt")
for(idir in dsubDirList){
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks')]
for(i in 1:nrow(dsub)){
if(!is.na(dsub$aciks[i])){
tmp1=as.numeric(dsub$cik[i])
if(grepl(" ",dsub$aciks[i])){
tmp2=as.numeric(unlist(strsplit(dsub$aciks[i]," ")))
} else{
tmp2=as.numeric(dsub$aciks[i])
}
tmp2=tmp2[nchar(as.character(tmp2))>2]
tmp=unique(c(tmp1,tmp2))
tmp=tmp[!is.na(tmp)]
if(sum(tmp %in% c(3153,41091),na.rm = T)>1){
#print(i)
}
slTmp=tmp1
resMapped=rbind(resMapped,data.frame(source=slTmp,target=tmp,stringsAsFactors = F))
}
}
}
resMapped=resMapped[-1,]
resMapped=resMapped[resMapped$source!=resMapped$target,]
idir
i
tmp
tmp2
tmp1
is.na(dsub$aciks[i])
dsub$aciks[i]
!is.na(dsub$aciks[i]) & dsub$aciks!=""
!is.na(dsub$aciks[i]) & dsub$aciks[i]!=""
resMapped=data.frame(source=1,target=2,stringsAsFactors = F)
dsubDirList=paste0("~/OneDrive - UC San Diego/stock_analysis/SEC/data/",dir("~/OneDrive - UC San Diego/stock_analysis/SEC/data/"),"/sub.txt")
for(idir in dsubDirList){
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks')]
for(i in 1:nrow(dsub)){
if(!is.na(dsub$aciks[i]) & dsub$aciks[i]!=""){
tmp1=as.numeric(dsub$cik[i])
if(grepl(" ",dsub$aciks[i])){
tmp2=as.numeric(unlist(strsplit(dsub$aciks[i]," ")))
} else{
tmp2=as.numeric(dsub$aciks[i])
}
tmp2=tmp2[nchar(as.character(tmp2))>2]
tmp=unique(c(tmp1,tmp2))
tmp=tmp[!is.na(tmp)]
if(sum(tmp %in% c(3153,41091),na.rm = T)>1){
#print(i)
}
slTmp=tmp1
resMapped=rbind(resMapped,data.frame(source=slTmp,target=tmp,stringsAsFactors = F))
}
}
}
resMapped=resMapped[-1,]
resMapped=resMapped[resMapped$source!=resMapped$target,]
name=paste0(resMapped$source,"_",resMapped$target)
name=paste0(resMapped$source,"_",resMapped$target)
resMapped=resMapped[!duplicated(name),]
head(resMapped)
dim(resMapped)
sum(resMapped$source== 1067983)
sum(resMapped$target== 1067983)
load(paste0("downloads/","stock_",inputDate,"/",files$fileName[i]))
rm(list=ls())
#reading in SEC data
evaluate_input <- function(input) {
# if input is a .html file
if(file.exists(input)) {
char.vec <- readLines(input, warn = FALSE)
return(paste(char.vec, collapse = ""))
}
# if input is html text
if(grepl("</html>", input, fixed = TRUE)) return(input)
# if input is a URL, probably should use a regex here instead?
if(!grepl(" ", input)) {
# downolad SSL certificate in case of https problem
if(!file.exists("cacert.perm")) download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.perm")
dl <- try(readLines(input, warn = FALSE), silent = TRUE)
if (inherits(dl, "try-error")) {
dl <- try(getURL(input, followlocation = TRUE, cainfo = "cacert.perm"), silent = TRUE)
if (inherits(dl, "try-error")) {
if (inherits(dl, "try-error")) {
dl <- try(getURL(input, followlocation = TRUE, cainfo = "cacert.perm"), silent = TRUE)
if (inherits(dl, "try-error")) {
dl=""
}
}
}
} else {
dl=paste(dl, collapse = "")
}
return(dl)
}
# return NULL if none of the conditions above apply
return(NULL)
}
# convert HTML to plain text
convert_html_to_text <- function(html) {
doc <- htmlParse(html, asText = TRUE)
text <- xpathSApply(doc, "//text()[not(ancestor::script)][not(ancestor::style)][not(ancestor::noscript)][not(ancestor::form)]", xmlValue)
return(text)
}
# format text vector into one character string
collapse_text <- function(txt) {
return(paste(txt, collapse = " "))
}
.htmlToText <- function(input,keepTrTd=FALSE, ...) {
###---PACKAGES ---###
require(RCurl)
require(XML)
###--- LOCAL FUNCTIONS ---###
# Determine how to grab html for a single input element
###--- MAIN ---###
# STEP 1: Evaluate input/Download the webpage
html.list <- list(evaluate_input(input))
if(keepTrTd){
html.list=list(gsub("</td>","|td|",unlist(html.list)))
html.list=list(gsub("</tr>","|tr|",unlist(html.list)))
html.list=list(gsub("<table","|table_s|<table",unlist(html.list)))
html.list=list(gsub("</table>","</table>|table_e|",unlist(html.list)))
}
# STEP 2: Extract text from HTML
text.list <- lapply(html.list, convert_html_to_text)
# STEP 3: Return text
text.vector <- sapply(text.list, collapse_text)
return(text.vector)
}
.myTrimFn <- function (x) gsub("^\\s+|\\s+$", "", x)
.mySubStrCountFn=function(inputSubStr,inputStr){
x=strsplit(inputStr,split = inputSubStr,fixed = T)
x=unlist(x)
return(length(x))
}
.myNameToCodeFn=function(inputCompanyName){
google.URL=paste0("http://stocks.tradingcharts.com/stocks/symbols/s/all/",paste(unlist(strsplit(inputCompanyName," ")),collapse = "+"),"+stock+name")
google.URL=paste0("https://www.google.com/search?q=",paste(unlist(strsplit("alphabet inc"," ")),collapse = "+"),"&tbm=fin")
txt <- .htmlToText(google.URL,keepTrTd = T)
txt <- iconv(txt,"WINDOWS-1252","UTF-8")
indx=regexpr("About",txt,fixed = T)
txt=substr(txt,indx+1,nchar(txt))
indx=regexpr("|table_s|",txt,fixed = T)
txt=substr(txt,0,indx-1)
txt=unname(sapply(txt, tolower))
}
.myGetCIK = function(ticker) {
require(XML)
require(RCurl)
stopifnot(is.character(ticker))
uri = "https://www.sec.gov/cgi-bin/browse-edgar"
response = getForm(uri,CIK=ticker,action="getcompany")
html = htmlParse(response)
CIKNode = getNodeSet(html, "//acronym[@title=\"Central Index Key\"][text() = \"CIK\"]")
CIKNodeText = sapply(CIKNode, function(x) xmlValue(getSibling(getSibling(x))))
CIK = sub(" .*","",CIKNodeText)
CIK = sub("^0*","",CIK)
return(CIK)
}
.myNetCombination=function(inputNet,order=T){
#This function returns a name for each interaction in the input network
inputNet$Fnode=as.character(inputNet$Fnode)
inputNet$Snode=as.character(inputNet$Snode)
if(order){
tst1=apply(inputNet[,c("Fnode","Snode")],1,min)
tst2=apply(inputNet[,c("Fnode","Snode")],1,max)
res=paste(tst1,tst2,sep=".")
} else {
res=paste(inputNet$Fnode,inputNet$Snode,sep=".")
}
return(res)
}
rm(list=ls())
#reading in SEC data
evaluate_input <- function(input) {
# if input is a .html file
if(file.exists(input)) {
char.vec <- readLines(input, warn = FALSE)
return(paste(char.vec, collapse = ""))
}
# if input is html text
if(grepl("</html>", input, fixed = TRUE)) return(input)
# if input is a URL, probably should use a regex here instead?
if(!grepl(" ", input)) {
# downolad SSL certificate in case of https problem
if(!file.exists("cacert.perm")) download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.perm")
dl <- try(readLines(input, warn = FALSE), silent = TRUE)
if (inherits(dl, "try-error")) {
dl <- try(getURL(input, followlocation = TRUE, cainfo = "cacert.perm"), silent = TRUE)
if (inherits(dl, "try-error")) {
if (inherits(dl, "try-error")) {
dl <- try(getURL(input, followlocation = TRUE, cainfo = "cacert.perm"), silent = TRUE)
if (inherits(dl, "try-error")) {
dl=""
}
}
}
} else {
dl=paste(dl, collapse = "")
}
return(dl)
}
# return NULL if none of the conditions above apply
return(NULL)
}
# convert HTML to plain text
convert_html_to_text <- function(html) {
doc <- htmlParse(html, asText = TRUE)
text <- xpathSApply(doc, "//text()[not(ancestor::script)][not(ancestor::style)][not(ancestor::noscript)][not(ancestor::form)]", xmlValue)
return(text)
}
# format text vector into one character string
collapse_text <- function(txt) {
return(paste(txt, collapse = " "))
}
.htmlToText <- function(input,keepTrTd=FALSE, ...) {
###---PACKAGES ---###
require(RCurl)
require(XML)
###--- LOCAL FUNCTIONS ---###
# Determine how to grab html for a single input element
###--- MAIN ---###
# STEP 1: Evaluate input/Download the webpage
html.list <- list(evaluate_input(input))
if(keepTrTd){
html.list=list(gsub("</td>","|td|",unlist(html.list)))
html.list=list(gsub("</tr>","|tr|",unlist(html.list)))
html.list=list(gsub("<table","|table_s|<table",unlist(html.list)))
html.list=list(gsub("</table>","</table>|table_e|",unlist(html.list)))
}
# STEP 2: Extract text from HTML
text.list <- lapply(html.list, convert_html_to_text)
# STEP 3: Return text
text.vector <- sapply(text.list, collapse_text)
return(text.vector)
}
.myTrimFn <- function (x) gsub("^\\s+|\\s+$", "", x)
.mySubStrCountFn=function(inputSubStr,inputStr){
x=strsplit(inputStr,split = inputSubStr,fixed = T)
x=unlist(x)
return(length(x))
}
.myNameToCodeFn=function(inputCompanyName){
google.URL=paste0("http://stocks.tradingcharts.com/stocks/symbols/s/all/",paste(unlist(strsplit(inputCompanyName," ")),collapse = "+"),"+stock+name")
google.URL=paste0("https://www.google.com/search?q=",paste(unlist(strsplit("alphabet inc"," ")),collapse = "+"),"&tbm=fin")
txt <- .htmlToText(google.URL,keepTrTd = T)
txt <- iconv(txt,"WINDOWS-1252","UTF-8")
indx=regexpr("About",txt,fixed = T)
txt=substr(txt,indx+1,nchar(txt))
indx=regexpr("|table_s|",txt,fixed = T)
txt=substr(txt,0,indx-1)
txt=unname(sapply(txt, tolower))
}
.myGetCIK = function(ticker) {
require(XML)
require(RCurl)
stopifnot(is.character(ticker))
uri = "https://www.sec.gov/cgi-bin/browse-edgar"
response = getForm(uri,CIK=ticker,action="getcompany")
html = htmlParse(response)
CIKNode = getNodeSet(html, "//acronym[@title=\"Central Index Key\"][text() = \"CIK\"]")
CIKNodeText = sapply(CIKNode, function(x) xmlValue(getSibling(getSibling(x))))
CIK = sub(" .*","",CIKNodeText)
CIK = sub("^0*","",CIK)
return(CIK)
}
.myNetCombination=function(inputNet,order=T){
#This function returns a name for each interaction in the input network
inputNet$Fnode=as.character(inputNet$Fnode)
inputNet$Snode=as.character(inputNet$Snode)
if(order){
tst1=apply(inputNet[,c("Fnode","Snode")],1,min)
tst2=apply(inputNet[,c("Fnode","Snode")],1,max)
res=paste(tst1,tst2,sep=".")
} else {
res=paste(inputNet$Fnode,inputNet$Snode,sep=".")
}
return(res)
}
##downloading the CIKs based on tickers
.myCIKdownloaderFn=function(companiesPath){
load(companiesPath)
resDf=data.frame(ticker="a",cik=1,stringsAsFactors = F)
for(i in companyLists$symbol){
print(i)
tmp=.myGetCIK(i)
if(length(tmp)>0){
resDf=rbind(resDf,data.frame(ticker=i,cik=as.numeric(tmp),stringsAsFactors = F))
}
}
resDf=resDf[-1,]
}
load("~/OneDrive - UC San Diego/stock_analysis/SEC/ciks.rda")
sum(is.na(resDf$cik))
sum(is.na(resDf$ticker))
mapper=read.table('~/OneDrive - UC San Diego/stock_analysis/SEC/CIKs.txt',header = T,sep="\t",stringsAsFactors = F)
sum(is.na(mapper$CIK))
sum(is.na(mapper$Ticker))
head(mapper)
dim(mapper)
dim(resDf)
length(unique(mapper$Ticker))
mapper=merge(mapper,resDf,by.x='CIK',by.y='cik',all=T)
dim(mapper)
head(mapper)
idir
resParents=data.frame(source=1,target=2,stringsAsFactors = F)
resSections=data.frame(source=1,target=2,stringsAsFactors = F)
dsubDirList=paste0("~/OneDrive - UC San Diego/stock_analysis/SEC/data/",dir("~/OneDrive - UC San Diego/stock_analysis/SEC/data/"),"/sub.txt")
idir=dsubDirList[1]
idir
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks')]
head(dsub)
for(idir in dsubDirList){
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks')]
resSections=rbind(resSections,data.frame(cik=dsub$cik,sic=dsub$sic,stringsAsFactors = F))
for(i in 1:nrow(dsub)){
if(!is.na(dsub$aciks[i]) & dsub$aciks[i]!=""){
tmp1=as.numeric(dsub$cik[i])
if(grepl(" ",dsub$aciks[i])){
tmp2=as.numeric(unlist(strsplit(dsub$aciks[i]," ")))
} else{
tmp2=as.numeric(dsub$aciks[i])
}
tmp2=tmp2[nchar(as.character(tmp2))>2]
tmp=unique(c(tmp1,tmp2))
tmp=tmp[!is.na(tmp)]
if(sum(tmp %in% c(3153,41091),na.rm = T)>1){
#print(i)
}
slTmp=tmp1
resParents=rbind(resParents,data.frame(source=slTmp,target=tmp,stringsAsFactors = F))
}
}
}
tmp1
dsub$cik
dsub$sic
resSections=rbind(resSections,data.frame(cik=dsub$cik,sic=dsub$sic,stringsAsFactors = F))
resSections
resParents=data.frame(source=1,target=2,stringsAsFactors = F)
resSections=data.frame(cik=1,sic=2,stringsAsFactors = F)
resSections
resParents=data.frame(source=1,target=2,stringsAsFactors = F)
resSections=data.frame(cik=1,sic=2,stringsAsFactors = F)
dsubDirList=paste0("~/OneDrive - UC San Diego/stock_analysis/SEC/data/",dir("~/OneDrive - UC San Diego/stock_analysis/SEC/data/"),"/sub.txt")
for(idir in dsubDirList){
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks')]
resSections=rbind(resSections,data.frame(cik=dsub$cik,sic=dsub$sic,stringsAsFactors = F))
for(i in 1:nrow(dsub)){
if(!is.na(dsub$aciks[i]) & dsub$aciks[i]!=""){
tmp1=as.numeric(dsub$cik[i])
if(grepl(" ",dsub$aciks[i])){
tmp2=as.numeric(unlist(strsplit(dsub$aciks[i]," ")))
} else{
tmp2=as.numeric(dsub$aciks[i])
}
tmp2=tmp2[nchar(as.character(tmp2))>2]
tmp=unique(c(tmp1,tmp2))
tmp=tmp[!is.na(tmp)]
if(sum(tmp %in% c(3153,41091),na.rm = T)>1){
#print(i)
}
slTmp=tmp1
resParents=rbind(resParents,data.frame(source=slTmp,target=tmp,stringsAsFactors = F))
}
}
}
resParents=resParents[-1,]
resSections=resSections[-1,]
resParents=resParents[resParents$source!=resParents$target,]
dim(resParents)
name=paste0(resParents$source,"_",resParents$target)
resParents=resParents[!duplicated(name),]
dim(resParents)
sum(resSections$cik %in% mapper$CIK)
dim(resSections)
x=resSections[!is.na(resSections$cik),]
x=x[!is.na(x$)m]
x=mapper[!is.na(mapper$CIK),]
x=x[!is.na(x$ticker)]
x=mapper[!is.na(mapper$ticker),]
x=x[!is.na(x$Ticker),]
dim(x)
all(x$ticker==x$Ticker)
which(x$ticker!=x$Ticker)
x[9,]
x[3083,]
x[1969,]
dim(resDf)
mapper=read.table('~/OneDrive - UC San Diego/stock_analysis/SEC/CIKs.txt',header = T,sep="\t",stringsAsFactors = F)
sum(resDf$ticker %in% mapper$Ticker)
mapper=merge(mapper,resDf,by.x='TICKER',by.y='ticker',all=T)
mapper=merge(mapper,resDf,by.x='Ticker',by.y='ticker',all=T)
dim(mapper)
x=mapper[which((!is.na(mapper$cik)) & (!is.na(mapper$CIK))),]
dim(x)
sum(duplicated(mapper$Ticker))
sum(duplicated(mapper$cik))
sum(duplicated(mapper$CIK))
dim(x)
all(x$cik==x$CIK)
which(x$cik !=x$CIK)
x[3453,]
mapper[mapper$CIK=="1334814",]
mapper[which(mapper$CIK==1334814),]
mapper[which(mapper$CIK==1617640),]
mapper[which(mapper$cik==1617640),]
resDf[resDf$cik==1617640,]
dim(resDf)
head(resDf)
data=read.table("~/OneDrive - UC San Diego/stock_analysis/SEC/data/2018q1/num.txt",sep="\t",header = T,stringsAsFactors = F,fill = T)
head(data)
dim(data)
length(unique(data$adsh))
data$tag[data$tag=="InterestPaid1"]="InterestPaid"
data$tag[data$tag=="EarningsPerShareDiluted1"]="EarningsPerShareDiluted"
data$tag[data$tag=="Goodwill1"]="Goodwill"
data$tag[data$tag=="Revenues"]="Revenue"
data$tag[data$tag=="Operatingrevenues"]="OperatingRevenues"
data$tag[data$tag=="InterestPaid1"]="InterestPaid"
data$tag[data$tag=="NumberOfLease"]="NumberOfLeases"
data$tag[data$tag=="Capital1"]="Capital"
slClmns=c("NetIncomeLoss","TemporaryEquityNetIncome","NetIncome","EarningsPerShareNetIncome","PercentageOfNetIncomeForeign","NetIncreaseDecreaseToNetIncome","Pretaxadjustednetincome","SharesOutstanding","OutstandingBorrowings","EarningsPerShareDiluted","EarningsPerShareDilutedCalculated","EarningsPerShareDilutedDistributed","EarningsPerShareDilutedUndistributed","UndistributedEarningsBasicandDiluted","BusinessEnterpriseValue","EnterpriseValueOfEmergingEntity")
slClmns=c(slClmns,"PrivilegedEnterpriseBenefitsRate","ReorganizationValueEnterpriseValue","EntityNumberOfEmployees","AverageNumberOfEmployees","NumberOfEmployees","EmployeesSalaryRate","BookValue","NetBookValue","BookValueOfAssetsSold","LongtermDebtBookValue")
slClmns=c(slClmns,"Revenue","NetRevenue","GrossRevenue")
slClmns=c(slClmns,"NetOperatingLoss","OperatingExpense","OperatingExpenses","OperatingEarnings","OperatingRevenues")
slClmns=c(slClmns,"ProfitsTax","TaxExposure","PreTaxIncome","PreTaxMargin","TaxableIncome","TaxRateChange","RevisedTaxRate","LossBeforeTaxes","TaxesOnEarnings")
slClmns=c(slClmns,"InterestPaid","InterestIncome","AccruedInterest","ImputedInterest","NonCashInterest","CarriedInterest","InterestExpense","InterestPaidNet","InterestPayable","PrepaidInterest","CarriedInterests","MineralInterests","InterestReceived","MinorityInterest","NoninterestIncome","NoninterestExpense","InterestIncomeCash","InterestRateMargin","InterestExpenseNet","InterestCommitment")
slClmns=c(slClmns,"BillingsToDate","CurrencyGainsLossesNet","EarnOutForeignCurrencyImpact")
slClmns=c(slClmns,"ApplicableTaxRate","ApplicableUSTaxRate","ComplementaryTaxRate","RevisedTaxRate","OriginalTaxRate")
slClmns=c(slClmns,"DebtTotal","DebtGross","DebtCurrent","LongTermDebt","DebtNoncurrent","DebtObligations")
slClmns=c(slClmns,"Capital","NetCapital","Cet1Capital","CapitalExpenditure","RiskToCapitalRatio","WorkingCapital")
slClmns=c(slClmns,"Cash","CashBurnRate","NetCash","DividendsPaidCash","CashOnHand","MarketableSecurities")
slClmns=c(slClmns,"WorkingCapital","NetWorkingCapital","WorkingCapitalDeficit","WorkingCapitalSurplus","NegativeWorkingCapital","IncreaseInWorkingCapital","WorkingCapitalDeficiency","WorkingCapitalSurplusDeficit","NetWorkingCapitalSettlements")
slClmns=c(slClmns,"PensionExpense","PensionIncomeExpense","PensionContributions","CorporatePensionAsset")
slClmns=c(slClmns,"LeaseCost","LeaseBonus","OperatingLeaseCost","LeaseInvestmentNet","LeaseFinancingNet","PaymentOfLeaseFee","AnnualLeaseFee","NumberOfLeases")
slClmns=c(slClmns,"FixedChargeCoverageRatio","FixedFeeContractRevenue")
slClmns=c(slClmns,"Goodwill","BookGoodwill","GoodwillSold")
data=data[data$tag %in% slClmns,]
dd=dcast(data = data,formula = adsh~tag,fun.aggregate = sum,value.var = "value")
library(stringi)
library(stringr)
library(stringi)
dd=dcast(data = data,formula = adsh~tag,fun.aggregate = sum,value.var = "value")
library(dplyr)
dsub1=merge(dsub,resDf,by = 'cik')
dim(dsub)
dim(dsub1)
dsub2=dsub[!(dsub$adsh %in% dsub1$adsh),]
dim(dsub2)
dim(mapper)
mapper=read.table('~/OneDrive - UC San Diego/stock_analysis/SEC/CIKs.txt',header = T,sep="\t",stringsAsFactors = F)
mapper=read.table('~/OneDrive - UC San Diego/stock_analysis/SEC/CIKs.txt',header = T,sep="\t",stringsAsFactors = F)
dim(mapper)
dsub2=merge(dsub2,mapper,by.x="cik",by.y='CIK')
dim(dsub2)
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dim(dsub2)
head(dsub)
dsub=read.table(idir,sep="\t",header = T,stringsAsFactors = F,comment.char = "",dec=NULL,quote ="")
head(dsub)
dsub=dsub[,c('adsh','cik','name','sic','fye','form','period','fy','fp','filed','aciks','stprba')]
dsub1=merge(dsub,resDf,by = 'cik')
dsub2=dsub[!(dsub$adsh %in% dsub1$adsh),]
dsub2=merge(dsub2,mapper,by.x="cik",by.y='CIK')
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
head(dsub2)
dim(dsub2)
dsub2=dsub2[which(dsub2$stprba==dsub2$Business),]
dim(dsub2)
head(dsub2)
dsub2=dsub[!(dsub$adsh %in% dsub1$adsh),]
dsub2=merge(dsub2,mapper,by.x="cik",by.y='CIK')
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dsub2[which(dsub2$stprba!=dsub2$Business),]
dsub2=dsub2[which(dsub2$stprba==dsub2$Business),]
dim(dsub)
dim(dsub1)
dim(dsub2)
dsub=rbind(dsub1,dsub2)
dsub1=merge(dsub,resDf,by = 'cik')
dsub2=dsub[!(dsub$adsh %in% dsub1$adsh),]
dsub2=merge(dsub2,mapper,by.x="cik",by.y='CIK')
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dsub2=dsub2[which(dsub2$sic==dsub2$SIC),]
dsub2=dsub2[which(dsub2$stprba==dsub2$Business),]
colnames(dsub1)
colnames(dsub2)
dsub=rbind(dsub1[,c("cik","adsh","sic","ticker","fye","fy")],dsub2[,c("cik","adsh","sic","ticker","fye","fy")])
colnames(dsub2)[colnames(dsub2)=="Ticker"]="ticker"
dsub=rbind(dsub1[,c("cik","adsh","sic","ticker","fye","fy")],dsub2[,c("cik","adsh","sic","ticker","fye","fy")])
dim(dsub)
which(dsub$ticker=="AAPL")
dsub[538,]
